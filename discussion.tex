\documentclass[doc,12pt]{apa}        % use: 'man' for submission type; 'jou' for
                                % journal type, and 'doc' for typical latex
                                % but with figures inline with text
\usepackage{geometry} 
%\geometry{a4paper} 
\usepackage[parfill]{parskip}   % paragraphs delimited by an empty line

\usepackage{graphicx} 
\usepackage{amssymb}            % no idea what this does...
\usepackage{epstopdf}           % no idea what this does...
%\usepackage{gensymb}            % no idea what this does...

\usepackage{setspace}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png} \setcounter{secnumdepth}{0}  % no idea what this does...

\usepackage{apacite}
\usepackage{longtable}
%%%%%%%%% END HEADER %%%%%%%%%

\title{Rewards are categories.} 
\author{Erik J. Peterson} \affiliation{Dept. of Psychology \\ Colorado State University \\ Fort Collins, CO} 

%%%%%%%%%%%%%%%%
\begin{document} 
%%%%%%%%%%%%%%%%
\maketitle
\doublespacing

\section{Discussion} % (fold)
\label{sec:dicussion}
To review, I wanted to know whether or not cognitive rewards are represented as categories in the human brain.  And whether such a representation might impact the reinforcement learning process.  To start to answer these two interrelated questions, I had participants complete a stimulus-response task using with pre-trained perceptual categories as rewards, one category for gains and one for losses.  And based on the behavioral and neural findings of this work, which I'll now discuss in detail, I conclude that cognitive rewards are indeed represented as categories.  And I'll further argue that category representations would be a reasonable mechanistic explanation for the generalization of secondary rewards.

\subsection{Taking us to can}
\label{sub:tocan}
In the behavioral task reward were literally categories, information integration (II) categories to be specific.  II is classic category structure, much studied in humans and other animals \cite{Smith:2011p9101,Ashby:2011p9148,Smith:2010p9713}.  II categories are distinct from their contemporaries by requiring integration of multi-dimensional stimulus information, and so are difficult to verbally describe, while recruiting procedural memory which relies heavily on the dorsal striatum \cite{Ashby:1998p9716}.   This lack of verbalizbility and multi-dimensionality make the reward categories irreconcilably different than the classical rewards almost universally used human subjects studies (e.g ''Win \$1'', ``Correct!'', ``Yes!'').  Despite this, participants easily and rapidly learned using the II categories.  Performance, as measured by both accuracy and reaction times, were nearly identical to similar tasks using verbal rewards (p\pageref{subsub:wellbehaved}).  

Further arguing for homology between the reward kinds, the overall pattern of BOLD activity, i.e. all trials compared to the rest trials (p\pageref{sub:blob}), was also markedly similar to that observed in nearly identical tasks using classical rewards (for several examples see, \citeA{LopezPaniagua:2011p8296,Seger:2010p7188,Cincotta:2007p6672,Seger:2006p5447,Seger:2005pd}).

The behavioral and neurological consistency observed in stimulus-response learning using classical and II reward categories means that perceptual categories can act as rewards and so, reversing that logic, rewards \emph{can be} categories.   Which leads naturally to the next analysis, whether the same neural algorithm(s) that mediate classical reward learning facilitate the reward categories actions as well.

\subsection{Are, Reflected in Error(s)}
\label{sub:inerror}
\subsubsection{A Known Pair's Logic}
\label{subsub:onestep}
However before making any claims on the modeling data, I need to get some logical preliminaries out of the way.  Many of the models of interest are both covariate and dependent.  Under generic statistical circumstance it is difficult, or even impossible, to compare the fit of such models.  However in limited cases strong, even casual, conclusions are possible.   Inside the same family and coding scheme, there is a single change between many of the models.  For example, ``rpe\_acc'' and ``rpe\_acc\_guass'' differ only by the similarity adjustment of the reward (i.e. Eq~\ref{eq:rg} and \ref{eq:Sgauss}).  Because both models are fit to the same data\footnote{Using the same deterministic loss function} and so have identical signal-to-noise ratios, the 1.5\footnote{Bilateral average} fold increase in information that comes from using ``rpe\_acc\_guass'' in the dorsal caudate \emph{must} be caused by that single change \cite{Pearl:2010p9726}.  So while 1.5 would be small increase when comparing two noisy random variates \cite{Anderson:2000p9475,Forster:2000p9623}, I argue that, (1) because uncertainty is constant between the fits, and (2) because we also know the exact relation between two models, and (3) that the models prediction's only sometimes diverge (compare columns in Figure~\ref{fig:rpeacc}), 1.5 should instead be considered strong evidence when paired models are compared.

\subsubsection{Categories, in All the Right Spots}
\label{subsub:rightspots}
In most of the regions of interest, the reward prediction family (``rpe'') was the most informative, ranging from 2.3-5.1 times more likely than the non-parametric ``boxcar'' model, p\pageref{subsub:belowctx}.  This alone strongly suggests that like classical rewards, the learning driven by reward categories are also mediated a dopaminergic reward prediction signal.  However, even more intriguing is the fact that many of the most sensitive reward prediction areas are best described by the Gaussian-similarity adjusted reward (Figures~\ref{fig:caudate},~\ref{fig:ant},~\ref{fig:post},~\ref{fig:insula}, and~\ref{fig:ofc}), strongly suggesting that category parameters (i.e. the similarity metrics) directly effect reward valuation.  This is a direct confirmation of my hypothesis that cognitive rewards have an underlying category representation.    

Of all studied brain regions, outside the VTA/SNc, striatal BOLD activity has been, time after time, shown to reflect the dopaminergic reward prediction error signal making it a, if not the, key test of novel reward prediction hypotheses (see the \emph{Introduction} for much supporting evidence on this point).  The fact then that the Gaussian-adjusted reward prediction term offers a substantively more informative account that the unadjusted models (Figure~\ref{fig:caudate}) is a is crucially important result.  Combined that is with the fact that the dorsal caudate was strongly active (Figure~\ref{fig:fvalcaudate}) and best described by the ``rpe'' family (Figure~\ref{fig:caudate}).  
 
However ventral striatum was expected also to play a strong role in this task, as it is both the ventral and dorsal striatum activity that have been correlated with reward prediction activity \cite{ODoherty:2003p6329,Knutson:2007p1687,Schonberg:2007p518,Seger:2010p7188}.  This is not to say they are functionally homogeneous though \cite{Schonberg:2009p6669,ODoherty:2004p1269,Atallah:2007p1746}.  The dorsal caudate has been repeatedly linked to more abstract kinds of rewarding activity (e.g. task outcomes, fictive rewards, money compared to juice \cite{Tricomi:2008p6663,Lohrenz:2007p7240,Valentin:2009p7202}, for a review see \citeA{Grahn:2008p4654}).  While ventral activity as been associated more with hedonic valuations \cite{ODoherty:2004p1269}.  In fact fictive reward prediction errors correlated most significantly with activity in the dorsal striatum, while experienced prediction errors correlate with activity in the ventral striatum \cite{Lohrenz:2007p7240}.  However given this functional divide, and the dorsal caudate's established role in II category learning \cite{Ashby:1998p9716}, in hindsight it is no surprise then that only dorsal striatum was found to active in the task.

The dorsal striatum and ACC have several notable similarities.  Both, in part, due to dopaminergic projections from the VTA/SNc that modulate LTP via D1 receptors\cite{Schweimer:2006p9780}, are strongly involved in cognitive reward learning \cite{Atlas:2010p7566,Hayden:2009p6545,Rudebeck:2008p4712,Rolls:2008p7577,Quilodran:2008p2645,Hampton:2007p2983,Ernst:2004p3998}, with the BOLD signal often reflecting prediction errors in higher-order conditioning experiments \cite{seymour:2004aa} and fictive rewards \cite{Hayden:2009p6545}.  The ACC though appears to specialize in mediating between competing \emph{future} alternatives, especially in the context of effort required to achieve each option \cite{Quilodran:2008p2645}.  Though ACC BOLD activity has also been correlated with the uncertainty or volatility of upcoming rewards \cite{Behrens:2007p8839}.  The fact then the ACC also is most informatively described by the Guassian-adjusted reward prediction error is another strong piece of evidence supporting reward category representations.  

\emph{TODO -- Insula}: it is the only area to rank both codes well, suggesting both are present.  Dopamine and the insula, need cites.  I am going to bug Dan about this one as he has read on Insula's activities.

\emph{TODO -- what to say about Middle frontal and Putamen, the two areas that favor ``rpe\_acc''?}

\subsubsection{A fit inconsistency}
\label{subsub:inconsistency}
Both ``rpe\_acc'' and ``rpe\_gl'' fit the behavioral data better either of the corresponding similarity-adjusted models (Figure~\ref{fig:logL}).  If rewards are in fact categories the opposite pattern would be expected.  This inconsistency though has an strong alternative explanation.  Even with perfect performance, the largest possible value estimate is smaller for the adjusted models (as suggested by Figure~\ref{fig:fig:denvalue}, compare the maximum value peaks for ``rpe\_acc'' compared to ``rpe\_acc\_exp'' and ``rpe\_acc\_exp'').  These smaller value estimates result in lower probability estimates (via the softmax transform, Eq~\ref{eq:softmax}) and so result in lower log-likelihood scores (i.e. worse fits).  Despite this inherent limitation the adjusted models could be modified to give equivalent performance.  As the task is deterministic, once the optimal choices were learned the models could switch strategies and rely on ``working memory'', where they just do what they did last time.  This kind of working memory has recently been shown to be quite entangled with human reinforcement learning \cite{Collins:2012p9779}.  Alternatively the reward prediction errors could be renormalized based on the cumulative variance, following observations of just such behavior \cite{Tobler:2005p6373}.


\subsubsection{Back to the Secondary}
\label{sub:generalsense}
When conditioned as secondary reinforcers simple stimuli generalize well in humans and animals (for a review see p\pageref{subsub:birds}).  This generalization is by inference, i.e no direct reinforcement is needed \cite{Guttman:1956p8355,Nakamura:2006p9093,Smith:2011p9101}.  Mechanistically how such generalization occurs has not been studied.  Based on the success of the similarity-adjusted reward prediction errors above, I speculate that the even simple stimuli have fundamentally categorical representations.  And that these representations, via similarity-adjusted prediction errors, facilitate stimulus generalization.  In addition to perfectly matching Shepard's (1987) theoretical predictions for the degree of generalization (p\pageref{subsub:curves}), categorical representations of the kind studied here (p\pageref{subsub:catquant}) for secondary rewards would implicitly allow animal's to generalize on the first new example, matching the observed behavior.  A categorical basis for even simple stimuli is advantageous in non-generalization trials as well. The intrinsic noise in neuronal encoding means same stimulus viewed twice must have a different representation \cite{Ashby:1986p9783}.  A categorical representation would easily overcome such noisy encodings. 

\subsection{The big conclusion}
Based on the consistency between classical and reward categories, both behaviorally and in overall BOLD activity patterns, I first concluded that rewards \emph{can} be categories.  This, combined with the fact that reward categories generate reward predictions errors, and these errors strongly reflect category structure, and that categories offer a powerful and parsimonious explanation for the generalization of secondary reinforcers, I finally conclude that rewards \emph{are} categories.


\subsection{Future Work}
\label{sub:future}

\emph{TODO -- flesh these out}

If rewards are categories, the next question is whether rewards are \emph{only} categories.  While generalization (and so categories) may be universal \cite{Shepard:1987p9102}, specifics matter too.  In fact memory for specifics is at odds with generalizable (i.e. abstract) memories \cite{Atallah:2004p5466}. Given item and categories must always diverge, both item and category reward representations would be useful.  However these is a marked degree of overlap between the reward processing and category learning systems \cite{Seger:2010p7189,Ashby:2011p9148}.  While this overlap might be due to the fact that most categories (in the lab) are learned using rewards, there is an alternative if rewards are just a kind of category.  The overlapped activity could reflect one category building another (dissimilar) category.

Behavioral predictions (however see scaling, WM).

Reward categories would be useful for robots.

\clearpage
\newpage
\bibliography{bibmin}
%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%
